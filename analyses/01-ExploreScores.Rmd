---
title: "01-ExploreScores"
author: "Galina M. Jönsson"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---
<br />

## Introduction

<br />
The purpose of the expert review process is to determine whether the long-term resident butterfly trends produced by our occupancy model formulation are a plausible description of how species changed between 1900-1976, and reflects existing knowledge for species post-1976.
<br />
<br />
The participants completed an online questionnaire which asked them to assess each of 52 graphs depicting 52 species' annual occupancy estimates across Great Britain from 1900 to 2016. For each of the 52 species' graphs, participants were asked two identical questions: to separately score (1) the extent to which estimates (including the uncertainty ribbon) between 1900-1976 were a plausible description of species' trends, and (2) whether the estimates (including the uncertainty ribbon) between 1976-2016 reflect existing knowledge (i.e., before and after UKBMS' standardized monitoring was initiated). All questions were scored on a five point scale (Strongly agree; Agree; Neither agree nor disagree; Disagree; Strongly disagree).  
<br/>
<br/>
Disagreement with an occupancy trend indicates that it is not a plausible description nor/or adequately reflect the evidence for that species. 
<br/>
The **ten** participants scored both periods for each of 52 species' occupancy plots (i.e., 104 questions per participant) for a total of **1,040** answers. These were coded from -2 (Strongly disagree) to +2 (Strongly agree).

<br/>

### Hypotheses

<br/>
We will use the answers from the questionnaire to answer/explore the following hypotheses/statements: 

1. The model formulation inaccurately estimates butterfly occupancy.  
    + If true, we expect that across participants, mean scores for all 52 species and both time periods is zero or lower (i.e., average scores are no better than ‘Neither agree nor disagree’) with high unanimity.   
    + If true, we also expect that the mean scores and the unanimity scores across participants show no significant difference between the 52 species, not between the two time periods.  
    + 'Prescription': re-formulate model or abort mission.   
2. The model formulation accurately estimates occupancy for the later time period (1976-2016), but fails to do so for the early time period (1900-1976). 
    + If true, we expect that across participants, mean scores across all 52 species for the early time period is zero or lower (i.e., no better than ‘Neither agree nor disagree’), while mean scores for the later time period is zero or lower. Specifically, we expect that for each of the 52 individual species, the distance between mean scores across participants is lower for the early compared to the late time period.         
    + If true, we also expect that the mean scores and the unanimity scores across participants show no significant difference between the 52 species.  
    + 'Prescription': re-formulate model or do not use for early time period.   
3. The model formulation accurately estimates occupancy for the early time period, but fails to do so for the late time period. 
   + Like point 2 but 'reverse'
4. The model formulation fails to produce 'accurate/good' outputs for some species, i.e., some species are just hard to model.  
    + If true, we expect that across participants and time periods, mean scores for some, but not all, species is zero or lower (i.e., meaning that the participants average score was no better than ‘Neither agree nor disagree’). Specifically, we expect that the same individual species score poorly OR well (i.e, less than or greater than zero, respectively) for both time periods.
    + If true, we expect that the distance between mean scores across participants for the two time periods is low across all species. 
4. Some species are hard to model in the early time period (1900-1976)  
5. Some species are hard to model in the later time period (1976-2016)      

<br/>

### Format raw scores

<br />

The individual expert-level raw scores needed to reproduce the first code chunk presented below is not in the common domain as it could contain details that disclose the identities of individual experts. For this code chunk, `eval` is set to `FALSE` in this document; nonetheless, the final data set saved in the last line of this chunk, containing all expert scores with randomized identification numbers, is available in the `/data` sub-folder of this repository.   
```{r format-data, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
# Load required package(s)
require(tidyr); require(dplyr)

### Read first participant results
ex1 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp01/expertData__2022-03-22_app01.csv")
# Add participant ID number
ex1$ID <- rep("01", 52)
# pivot separate Q1 & Q2 result columns to a single column and an additional name indicating question number. Name data frame 'df'
df <- ex1 %>% pivot_longer(cols = starts_with("q"))

### Second participant results
ex2<-read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp02IK/expertData__2022-04-01_app02.csv")
ex2$ID <- rep("02", 52); df <- rbind(df, (ex2 %>% # Row bind with 'df'
                                            pivot_longer(cols = starts_with("q"))))
### Third participant results
ex3 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp03/expertData__2022-04-01_app03.csv")
ex3$ID <- rep("03", 52); df <- rbind(df, (ex3 %>% pivot_longer(cols = starts_with("q"))))
### Fourth participant results
ex4 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp04/expertData__2022-02-16_app04.csv")
ex4$ID <- rep("04", 52); df <- rbind(df, (ex4 %>% pivot_longer(cols = starts_with("q"))))
### Sixth participant results
ex6 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp06/expertData__2022-04-06_app06.csv")
ex6$ID <- rep("05", 52); df <- rbind(df, (ex6 %>% pivot_longer(cols = starts_with("q"))))
### Eighth participant results
ex8 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp08/expertData__2022-04-04_app08.csv")
ex8$ID <- rep("06", 52); df <- rbind(df, (ex8 %>% pivot_longer(cols = starts_with("q"))))
### Ninth participant results
ex09 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp09/expertData__2022-04-17_app09.csv")
ex09$ID <- rep("07", 52); df <- rbind(df, (ex09 %>% pivot_longer(cols = starts_with("q"))))
### Tenth participant results
ex10 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp10/expertData__2022-04-08_app10.csv")
ex10$ID <- rep("08", 52); df <- rbind(df, (ex10 %>% pivot_longer(cols = starts_with("q"))))
### Twelfth participant results
ex12 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp12/expertData__2022-04-01_app12.csv")
ex12$ID <- rep("09", 52); df <- rbind(df, (ex12 %>% pivot_longer(cols = starts_with("q"))))
### Thirteenth participant results
ex13 <- read.csv("../app_ExpertReviewForm/ParticipantApps/appLepTrendExOp13/expertData__2022-04-08_app13.csv")
ex13$ID <- rep("10", 52); df <- rbind(df, (ex13 %>% pivot_longer(cols = starts_with("q"))))

### Rename ambiguous column names
names(df)[names(df) == 'name'] <- 'question'; names(df)[names(df) == 'value'] <- 'score' 

### Save collated raw expert scores as csv.file
#write.csv(df[c("spp_name","com_name","ID","question","score")] , file="ExperstScores_Raw.csv", row.names=F)
```
<br/>
<br/>

The experts scored both questions on five-point Likert scales (ranging from “strongly agree” to “strongly disagree”) to capture information on experts’ degree of confidence. Below, I re-format the scores numerically from -2 (Strongly disagree) to +2 (Strongly agree). 


```{r scale-raw-data, eval=TRUE, echo=TRUE, warning=FALSE, message=FALSE}
### Load required package(s)
require(tidyr); require(dplyr)
### Read collated raw expert scores
df <- read.csv("../data/ExperstScores_Raw.csv")
### re-code responses from -2 (strongly disagree) to +2 (strongly agree)
df$score <- df$score-3
### specify variable "ID" as discrete factor and order level 
df$ID <- as.factor(as.character(df$ID))
df$ID <- ordered(df$ID, levels = c("1", "2", "3", "4", "5", "6", "7",
                                     "8", "9", "10"))
```
<br/>
<br/>


## Data Visualisation

<br/>
Let's first look at the distribution of all scores across experts and species per questions referring to each of the two time periods (i.e. pre-1976 and post-1976).
<br/>
<br/>
```{r figureA, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
require("dplyr"); require("RColorBrewer"); require("R.utils"); require("ggplot2"); require("wesanderson")

# new response column based on multiple conditions:
dftemp <- df %>% mutate(response = 
                          case_when(score == -2 ~ "Strongly disagree", 
                                    score == -1 ~ "Disagree", 
                                    score == 0 ~ "Neither agree nor disagree", 
                                    score == 1 ~ "Agree",
                                    score == 2 ~ "Strongly agree"))

names(dftemp)[names(dftemp) == "question"] <- "Time_Period"
dftemp[dftemp$'Time_Period'=="q1", "Time_Period"] <- "1900-1976"
dftemp[dftemp$'Time_Period'=="q2", "Time_Period"] <- "1976-2015"

dftemp <- dftemp %>%
	group_by(Time_Period, response) %>%  # grouping by these two variables
	tally() %>%  # counting the number of responses
	mutate(perc = n / sum(n) * 100) %>%
	dplyr::select(-n) %>%
	group_by(Time_Period) %>%
	spread(response, perc)
# Remove NA column
dftemp <- dftemp[,-7]

dftemp <- dftemp %>%
	mutate(midlow = `Neither agree nor disagree` / 2,
		midhigh = `Neither agree nor disagree` / 2) %>%
	dplyr::select(Time_Period, 'Strongly disagree', 'Disagree', midlow, midhigh, 'Agree', 'Strongly agree') %>%
	gather(key = response, value = perc, 2:7) %>%
	`colnames<-`(c("Time_Period", "response", "perc"))

df_plot_hi <- dftemp %>%
	filter(response %in% c('Strongly agree', 'Agree' , 'midhigh')) %>%
	mutate(response = factor(response, levels = c('Strongly agree', 'Agree' , 'midhigh')))

df_plot_lo <- dftemp %>%
	filter(response %in% c("midlow", "Disagree", "Strongly disagree")) %>%
	mutate(response = factor(response, levels = c("Strongly disagree", "Disagree", "midlow")))

# Use wesanderson to store a preset diverging colour palette as a vector of colour codes
mycols <- wes_palette("Zissou1", n=15, type="continuous")[c(12,8,7,5,1)]
# Duplicate the middle value since "Neither agree nor disagree" is two groups: "midhigh" and "midlow"
mycols <- insert(mycols, ats = 3, wes_palette("Zissou1", n=10, type="continuous")[c(5)])
# Replace the ugly white colour for "Neither agree nor disagree" with a pleasant dishwater grey
mycols <- gsub("#CAC656", "#9C9C9C", mycols) # <0%
mycols <- gsub("#D1C74C", "#9C9C9C", mycols) # >0%
# Assign names to the vector based on the colours we want for each group
names(mycols) <- c('Strongly disagree', 'Disagree', 'midhigh', 'midlow', "Agree", "Strongly agree")

### Plot figure
pA <- ggplot() +
	geom_bar(data = df_plot_hi, aes(x = Time_Period, y=perc, fill = response), stat="identity") +
	geom_bar(data = df_plot_lo, aes(x = Time_Period, y=-perc, fill = response), stat="identity") +
	geom_hline(yintercept = 0, color =c("black")) +
	scale_fill_manual(values = mycols,
		breaks = c('Strongly agree', 'Agree', 'midhigh', "Disagree", "Strongly disagree"),
		labels = c('Strongly agree', 'Agree', 'Neither agree nor disagree', "Disagree", "Strongly disagree")) +
	coord_flip() +
	labs(x = "Time Period", 
	     y = "Percentage of answers (%)",
       fill = "Score",
       title = "Figure A: Distribution of all scores for each time period",
       subtitle = "Across species and participants") +
	theme_classic() +
  theme(text = element_text(size = 14)) 

pA
```
<br/>
<br/>


Next, I visualise the mean and variance for each participant separately for each question (i.e. pre-1976 and post-1976) across the 52 species.
<br/>
```{r figureB, eval=TRUE, echo=FALSE, cache=FALSE, warning=FALSE, message=FALSE}
### Load required package(s)
require(tidyr); require(dplyr); require(ggplot2)

### specify variable "question" (corresponding to time period) as discrete factor
df$question <- as.factor(df$question)

######################################################################
### Mean score against variance per participant ID


### Subset and summarise response data
df2 <- as.data.frame(na.omit(df[, c("ID", "question", "score")]) 
                     %>% group_by(ID, question) 
                     %>% summarise(Mean = mean(score), Variance = (var(score))))

### Define colour blind friendly palette
cbPalette <- c(#"#000000",  # "#999999", 
               "grey36", "#E69F00", "#009E73", "#66CC99",
               "#F0E442","#56B4E9", "#0072B2",  "#9999CC",
               "#CC79A7", "#D55E00") # , "#9E0142")

### Graph
p <- ggplot() + 
  geom_line(aes(Mean, Variance, group = ID), df2, color="grey") + # Line between same species' time periods
  geom_point(aes(Mean, Variance, shape=question, size=question, colour=ID), 
             df2, size=4.5, position = "jitter") + 
  scale_shape_manual(name="\nTime Period", 
                     values=c(18,20), 
                     labels = c("1900-1976", "1976-2016")) +
  scale_colour_manual(name="Participant ID", values=cbPalette) +
  labs(x = "Mean Score",
       y = "
       Variance",
       title = "Figure B: Mean score against variance per participant ID",
       subtitle = "Summarised across species for each time period") +
  theme(legend.key = element_rect(fill = "white", colour = NA)) +
  theme(panel.background = element_rect(fill = "white", colour = "black")) +
  guides(size = "none",
         shape = guide_legend(order=1),
         colour = guide_legend(order=2)) +
  # ID legend colour shape different to either time period
    guides(colour = guide_legend(override.aes = list(shape = c(15,15,15,15,15,15,15,15,15,15),
                                                     size = 3.7))) + 
  theme(text = element_text(size = 14))
p
```
<br/>
<br/>
**General trends: Mean Scores**  

* On average across species, all participants score post-1976 trends (diamond) higher than pre-1976 trends (triangle). 
* All but one participants' (ID 09) mean score across the two time periods (circles) are greater than zero meaning that these participants average scores were generally better than ‘Neither agree nor disagree’.<br/>
* All participants, on average, scored post-1976 trends above zero, indicating that generally, there is some level of agreement/plausibility for the late time period. <br/>
* Three of ten participants' mean scores for the 'pre-1976' periods (triangle) are negative (04, 09 and 10), i.e., no better than ‘Neither agree nor disagree’ and instead, more likely to be disagreed, than agreed, with.  <br/>
    + One participant (ID 09) stands out as scoring lower than others across all questions.<br/>
<br/>   

**General trends: Variance**  

* The variance among scores for pre-1976 trends (triangle) are generally greater than for post-1976 trends (diamond). 
* Most participants' difference between pre-1976 trends' (triangle) and post-1976 trends' (diamond) score variances are around, or just above, 0.05; however, three participants relative variance differences deviate from the generality. Namely, ID01, ID06 and ID10, whose answers tend to be more consistent/unanimous to questions on the later time series while answers for the early part of the time series vary more depending on species.<br/>
<br />

***
Next, I also calculate the mean and variance for each species across participants, and measured the unanimity across participants as 1-variance (Figure C).
of the time series vary more depending on species.<br/>
<br />
<br />


```{r figureC, eval=TRUE, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
### Load required package(s)
require(tidyr); require(dplyr); require(ggplot2); require(RColorBrewer)

### Define constraint Line
constraintLine <- data.frame(nMax = as.numeric(0:10), nMin = as.numeric(10:0),
                             mean = as.numeric(rep(NA, 11)), # To populate
                             unanimity = as.numeric(rep(NA, 11))) # To populate
# Loop through each row with number of possible extremes (2 or -2) 
for(i in 1:nrow(constraintLine)){ # For each row, create a vector with ten (10) elements:
  temp <- append(rep(-2, constraintLine$nMax[[i]]), # nMax times 2 ('Strongly agree')
                 rep(2, constraintLine$nMin[[i]])) # nMin times -2 ('Strongly disagree')
  constraintLine$mean[[i]] <- mean(temp) # Use vector to find mean
  constraintLine$unanimity[[i]] <- 1-var(temp) # and unanimity
}

### Subset and summarise response data
df3 <- as.data.frame(na.omit(df[, c("spp_name", "question", "score")]) %>% 
                       group_by(spp_name, question) %>% 
                       summarise(Mean = mean(score), Unanimity = (1 - (var(score)))))

# Define colours
cols <- c("#E69F00", "#009E73")

### Graph
q <- ggplot(df3, aes(Mean, Unanimity)) + 
  geom_line(aes(group = spp_name), color="grey") + # Line between same species' time periods
  geom_jitter(width = 0.04, height = 0.04, 
              aes(group = question, shape=question, colour=question),
              size=3.5) + # use jitter over geom_points to reveal overlapping points
  geom_line(aes(mean, unanimity), constraintLine) + # Add constraint line
  scale_shape_manual("Time Period", 
                     values=c(18,20),
                     labels = c("1900-1976", "1976-2016")) +
  scale_colour_manual("Time Period", values=cols,
                      labels = c("1900-1976", "1976-2016")) +
  labs(x = "Mean Score", y = "
       Unanimity",
       title ="Figure C: Mean score per sp. against unanimity (1-variance)",
       subtitle = "Summarised across expert respondents for each time period") +
  theme(legend.key = element_rect(fill = "white", color = NA)) +
  theme(panel.background=element_rect(fill="white", colour="black")) +
  coord_cartesian(ylim=c(-1.6, 1)) +
  theme(text = element_text(size = 14))   
q
```
<br />
<br />
